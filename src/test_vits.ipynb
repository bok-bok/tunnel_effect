{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-42b4d75daa57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ImageNet100_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "from timm.models.vision_transformer import VisionTransformer, vit_base_patch16_224, vit_small_patch16_36x1_224\n",
    "from transformers import ViTConfig,ViTModel,ViTForImageClassification\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, SubsetRandomSampler\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from .src.data_loader import get_ImageNet100_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_100_DIR = \"/home/tolga/data/imagenet100\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vit224 = timm.create_model('vit_base_patch8_224', pretrained=False)\n",
    "# timm.list_models(\"vit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_dict': True,\n",
       " 'output_hidden_states': False,\n",
       " 'output_attentions': False,\n",
       " 'torchscript': False,\n",
       " 'torch_dtype': None,\n",
       " 'use_bfloat16': False,\n",
       " 'tf_legacy_loss': False,\n",
       " 'pruned_heads': {},\n",
       " 'tie_word_embeddings': True,\n",
       " 'is_encoder_decoder': False,\n",
       " 'is_decoder': False,\n",
       " 'cross_attention_hidden_size': None,\n",
       " 'add_cross_attention': False,\n",
       " 'tie_encoder_decoder': False,\n",
       " 'max_length': 20,\n",
       " 'min_length': 0,\n",
       " 'do_sample': False,\n",
       " 'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'num_beam_groups': 1,\n",
       " 'diversity_penalty': 0.0,\n",
       " 'temperature': 1.0,\n",
       " 'top_k': 50,\n",
       " 'top_p': 1.0,\n",
       " 'typical_p': 1.0,\n",
       " 'repetition_penalty': 1.0,\n",
       " 'length_penalty': 1.0,\n",
       " 'no_repeat_ngram_size': 0,\n",
       " 'encoder_no_repeat_ngram_size': 0,\n",
       " 'bad_words_ids': None,\n",
       " 'num_return_sequences': 1,\n",
       " 'chunk_size_feed_forward': 0,\n",
       " 'output_scores': False,\n",
       " 'return_dict_in_generate': False,\n",
       " 'forced_bos_token_id': None,\n",
       " 'forced_eos_token_id': None,\n",
       " 'remove_invalid_values': False,\n",
       " 'exponential_decay_length_penalty': None,\n",
       " 'suppress_tokens': None,\n",
       " 'begin_suppress_tokens': None,\n",
       " 'architectures': None,\n",
       " 'finetuning_task': None,\n",
       " 'id2label': {0: 'LABEL_0',\n",
       "  1: 'LABEL_1',\n",
       "  2: 'LABEL_2',\n",
       "  3: 'LABEL_3',\n",
       "  4: 'LABEL_4',\n",
       "  5: 'LABEL_5',\n",
       "  6: 'LABEL_6',\n",
       "  7: 'LABEL_7',\n",
       "  8: 'LABEL_8',\n",
       "  9: 'LABEL_9',\n",
       "  10: 'LABEL_10',\n",
       "  11: 'LABEL_11',\n",
       "  12: 'LABEL_12',\n",
       "  13: 'LABEL_13',\n",
       "  14: 'LABEL_14',\n",
       "  15: 'LABEL_15',\n",
       "  16: 'LABEL_16',\n",
       "  17: 'LABEL_17',\n",
       "  18: 'LABEL_18',\n",
       "  19: 'LABEL_19',\n",
       "  20: 'LABEL_20',\n",
       "  21: 'LABEL_21',\n",
       "  22: 'LABEL_22',\n",
       "  23: 'LABEL_23',\n",
       "  24: 'LABEL_24',\n",
       "  25: 'LABEL_25',\n",
       "  26: 'LABEL_26',\n",
       "  27: 'LABEL_27',\n",
       "  28: 'LABEL_28',\n",
       "  29: 'LABEL_29',\n",
       "  30: 'LABEL_30',\n",
       "  31: 'LABEL_31',\n",
       "  32: 'LABEL_32',\n",
       "  33: 'LABEL_33',\n",
       "  34: 'LABEL_34',\n",
       "  35: 'LABEL_35',\n",
       "  36: 'LABEL_36',\n",
       "  37: 'LABEL_37',\n",
       "  38: 'LABEL_38',\n",
       "  39: 'LABEL_39',\n",
       "  40: 'LABEL_40',\n",
       "  41: 'LABEL_41',\n",
       "  42: 'LABEL_42',\n",
       "  43: 'LABEL_43',\n",
       "  44: 'LABEL_44',\n",
       "  45: 'LABEL_45',\n",
       "  46: 'LABEL_46',\n",
       "  47: 'LABEL_47',\n",
       "  48: 'LABEL_48',\n",
       "  49: 'LABEL_49',\n",
       "  50: 'LABEL_50',\n",
       "  51: 'LABEL_51',\n",
       "  52: 'LABEL_52',\n",
       "  53: 'LABEL_53',\n",
       "  54: 'LABEL_54',\n",
       "  55: 'LABEL_55',\n",
       "  56: 'LABEL_56',\n",
       "  57: 'LABEL_57',\n",
       "  58: 'LABEL_58',\n",
       "  59: 'LABEL_59',\n",
       "  60: 'LABEL_60',\n",
       "  61: 'LABEL_61',\n",
       "  62: 'LABEL_62',\n",
       "  63: 'LABEL_63',\n",
       "  64: 'LABEL_64',\n",
       "  65: 'LABEL_65',\n",
       "  66: 'LABEL_66',\n",
       "  67: 'LABEL_67',\n",
       "  68: 'LABEL_68',\n",
       "  69: 'LABEL_69',\n",
       "  70: 'LABEL_70',\n",
       "  71: 'LABEL_71',\n",
       "  72: 'LABEL_72',\n",
       "  73: 'LABEL_73',\n",
       "  74: 'LABEL_74',\n",
       "  75: 'LABEL_75',\n",
       "  76: 'LABEL_76',\n",
       "  77: 'LABEL_77',\n",
       "  78: 'LABEL_78',\n",
       "  79: 'LABEL_79',\n",
       "  80: 'LABEL_80',\n",
       "  81: 'LABEL_81',\n",
       "  82: 'LABEL_82',\n",
       "  83: 'LABEL_83',\n",
       "  84: 'LABEL_84',\n",
       "  85: 'LABEL_85',\n",
       "  86: 'LABEL_86',\n",
       "  87: 'LABEL_87',\n",
       "  88: 'LABEL_88',\n",
       "  89: 'LABEL_89',\n",
       "  90: 'LABEL_90',\n",
       "  91: 'LABEL_91',\n",
       "  92: 'LABEL_92',\n",
       "  93: 'LABEL_93',\n",
       "  94: 'LABEL_94',\n",
       "  95: 'LABEL_95',\n",
       "  96: 'LABEL_96',\n",
       "  97: 'LABEL_97',\n",
       "  98: 'LABEL_98',\n",
       "  99: 'LABEL_99'},\n",
       " 'label2id': {'LABEL_0': 0,\n",
       "  'LABEL_1': 1,\n",
       "  'LABEL_2': 2,\n",
       "  'LABEL_3': 3,\n",
       "  'LABEL_4': 4,\n",
       "  'LABEL_5': 5,\n",
       "  'LABEL_6': 6,\n",
       "  'LABEL_7': 7,\n",
       "  'LABEL_8': 8,\n",
       "  'LABEL_9': 9,\n",
       "  'LABEL_10': 10,\n",
       "  'LABEL_11': 11,\n",
       "  'LABEL_12': 12,\n",
       "  'LABEL_13': 13,\n",
       "  'LABEL_14': 14,\n",
       "  'LABEL_15': 15,\n",
       "  'LABEL_16': 16,\n",
       "  'LABEL_17': 17,\n",
       "  'LABEL_18': 18,\n",
       "  'LABEL_19': 19,\n",
       "  'LABEL_20': 20,\n",
       "  'LABEL_21': 21,\n",
       "  'LABEL_22': 22,\n",
       "  'LABEL_23': 23,\n",
       "  'LABEL_24': 24,\n",
       "  'LABEL_25': 25,\n",
       "  'LABEL_26': 26,\n",
       "  'LABEL_27': 27,\n",
       "  'LABEL_28': 28,\n",
       "  'LABEL_29': 29,\n",
       "  'LABEL_30': 30,\n",
       "  'LABEL_31': 31,\n",
       "  'LABEL_32': 32,\n",
       "  'LABEL_33': 33,\n",
       "  'LABEL_34': 34,\n",
       "  'LABEL_35': 35,\n",
       "  'LABEL_36': 36,\n",
       "  'LABEL_37': 37,\n",
       "  'LABEL_38': 38,\n",
       "  'LABEL_39': 39,\n",
       "  'LABEL_40': 40,\n",
       "  'LABEL_41': 41,\n",
       "  'LABEL_42': 42,\n",
       "  'LABEL_43': 43,\n",
       "  'LABEL_44': 44,\n",
       "  'LABEL_45': 45,\n",
       "  'LABEL_46': 46,\n",
       "  'LABEL_47': 47,\n",
       "  'LABEL_48': 48,\n",
       "  'LABEL_49': 49,\n",
       "  'LABEL_50': 50,\n",
       "  'LABEL_51': 51,\n",
       "  'LABEL_52': 52,\n",
       "  'LABEL_53': 53,\n",
       "  'LABEL_54': 54,\n",
       "  'LABEL_55': 55,\n",
       "  'LABEL_56': 56,\n",
       "  'LABEL_57': 57,\n",
       "  'LABEL_58': 58,\n",
       "  'LABEL_59': 59,\n",
       "  'LABEL_60': 60,\n",
       "  'LABEL_61': 61,\n",
       "  'LABEL_62': 62,\n",
       "  'LABEL_63': 63,\n",
       "  'LABEL_64': 64,\n",
       "  'LABEL_65': 65,\n",
       "  'LABEL_66': 66,\n",
       "  'LABEL_67': 67,\n",
       "  'LABEL_68': 68,\n",
       "  'LABEL_69': 69,\n",
       "  'LABEL_70': 70,\n",
       "  'LABEL_71': 71,\n",
       "  'LABEL_72': 72,\n",
       "  'LABEL_73': 73,\n",
       "  'LABEL_74': 74,\n",
       "  'LABEL_75': 75,\n",
       "  'LABEL_76': 76,\n",
       "  'LABEL_77': 77,\n",
       "  'LABEL_78': 78,\n",
       "  'LABEL_79': 79,\n",
       "  'LABEL_80': 80,\n",
       "  'LABEL_81': 81,\n",
       "  'LABEL_82': 82,\n",
       "  'LABEL_83': 83,\n",
       "  'LABEL_84': 84,\n",
       "  'LABEL_85': 85,\n",
       "  'LABEL_86': 86,\n",
       "  'LABEL_87': 87,\n",
       "  'LABEL_88': 88,\n",
       "  'LABEL_89': 89,\n",
       "  'LABEL_90': 90,\n",
       "  'LABEL_91': 91,\n",
       "  'LABEL_92': 92,\n",
       "  'LABEL_93': 93,\n",
       "  'LABEL_94': 94,\n",
       "  'LABEL_95': 95,\n",
       "  'LABEL_96': 96,\n",
       "  'LABEL_97': 97,\n",
       "  'LABEL_98': 98,\n",
       "  'LABEL_99': 99},\n",
       " 'tokenizer_class': None,\n",
       " 'prefix': None,\n",
       " 'bos_token_id': None,\n",
       " 'pad_token_id': None,\n",
       " 'eos_token_id': None,\n",
       " 'sep_token_id': None,\n",
       " 'decoder_start_token_id': None,\n",
       " 'task_specific_params': None,\n",
       " 'problem_type': None,\n",
       " '_name_or_path': '',\n",
       " '_commit_hash': None,\n",
       " 'transformers_version': None,\n",
       " 'hidden_size': 768,\n",
       " 'num_hidden_layers': 12,\n",
       " 'num_attention_heads': 12,\n",
       " 'intermediate_size': 3072,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.0,\n",
       " 'attention_probs_dropout_prob': 0.0,\n",
       " 'initializer_range': 0.02,\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'image_size': 128,\n",
       " 'patch_size': 8,\n",
       " 'num_channels': 3,\n",
       " 'qkv_bias': True,\n",
       " 'encoder_stride': 16}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config128_8 = ViTConfig(image_size=128,patch_size=8,num_labels=100)\n",
    "config224_8 = ViTConfig(image_size=224,patch_size=8,num_labels = 100)\n",
    "\n",
    "vars(config128_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit128 = ViTForImageClassification(config128_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_ImageNet100_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ImageNet100 data with resolution 1024\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/datasets/ImageNet-100/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0e4f0d0439ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataloader, test_dataloader = get_ImageNet100_dataloader(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/tunnel_effect/src/data_loader.py\u001b[0m in \u001b[0;36mget_ImageNet100_dataloader\u001b[0;34m(resolution_size, batch_size, classes_num, use_all)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ImageNet100_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolution_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# get indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/datasets/ImageNet-100/train'"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader = get_ImageNet100_dataloader(\n",
    "    1024, 64, classes_num=None, use_all=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "def get_balanced_indices(dataset, dataset_name, dataset_type, samples_per_class=100, classes=None):\n",
    "    # create dir if not exits\n",
    "    save_dir = f\"values/{dataset_name}/indices\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    num_classes = len(dataset.classes)\n",
    "    if classes is not None:\n",
    "        num_classes = classes\n",
    "\n",
    "    if samples_per_class is not None:\n",
    "        # if file exists, return\n",
    "        file_dir = os.path.join(save_dir, f\"{dataset_type}_{num_classes}_{samples_per_class}.pt\")\n",
    "        if os.path.exists(file_dir):\n",
    "            print(f\"loading saved {dataset_name} balanced indices\")\n",
    "            return torch.load(file_dir)\n",
    "\n",
    "    if dataset_type not in [\"train\", \"val\"]:\n",
    "        raise ValueError(\"dataset_type must be train or val\")\n",
    "\n",
    "    # create new file if not exists\n",
    "    # get indices\n",
    "    print(\"creating new indices\")\n",
    "    indices = []\n",
    "    for class_idx in range(num_classes):\n",
    "        class_indices = np.where(np.array(dataset.targets) == class_idx)[0]\n",
    "        if samples_per_class is not None:\n",
    "            class_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
    "\n",
    "        indices.extend(class_indices)\n",
    "\n",
    "    save_path = f\"{save_dir}/{dataset_type}_{num_classes}_{samples_per_class}.pt\"\n",
    "    torch.save(indices, save_path)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagenet100DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, resolution_size, batch_size, num_workers, classes_num=None, use_all=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_dir = os.path.join(IMAGENET_100_DIR, \"train\")\n",
    "        self.test_dir  = os.path.join(IMAGENET_100_DIR, \"val\")\n",
    "        \n",
    "        self.resolution_size = resolution_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.classes_num = classes_num\n",
    "        self.use_all = use_all\n",
    "        \n",
    "    def get_ImageNet100_transforms(self,image_size):\n",
    "        train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        return train_transform, test_transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        data_name = \"imagenet100\"\n",
    "        train_transform, test_transform = self.get_ImageNet100_transforms(self.resolution_size)\n",
    "        \n",
    "        train_dataset = datasets.ImageFolder(root = self.train_dir, transform = train_transform)\n",
    "        \n",
    "        \n",
    "        if stage == \"fit\":\n",
    "            train_samples_per_class = 200 if self.use_all else None\n",
    "            train_dataset  = datasets.ImageFolder(root = self.train_dir,  transform = train_transform)\n",
    "            train_indices = get_balanced_indices(train_dataset, data_name, \"train\", train_samples_per_class, self.classes_num)\n",
    "            print(f\"train indices: {len(train_indices)}\")\n",
    "            self.train_subset = Subset(train_dataset, train_indices)\n",
    "\n",
    "        \n",
    "        if stage == \"test\":\n",
    "\n",
    "            test_samples_per_class = 50 if self.use_all else None\n",
    "            test_dataset  = datasets.ImageFolder(root = self.test_dir,  transform = test_transform)\n",
    "            test_indices = get_balanced_indices(test_dataset, data_name, \"val\", test_samples_per_class, self.classes_num)\n",
    "            print(f\"test indices: {len(test_indices)}\")\n",
    "            self.test_subset = Subset(test_dataset, test_indices)\n",
    "\n",
    "        \n",
    "        if stage == \"predict\":\n",
    "            pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_subset, batch_size = self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_subset, batch_size = self.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = Imagenet100DataModule(224, 64, 4, classes_num=None, use_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(devices=4,accelerator=\"gpu\",strategy=\"ddp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_dict': True,\n",
       " 'output_hidden_states': False,\n",
       " 'output_attentions': False,\n",
       " 'torchscript': False,\n",
       " 'torch_dtype': None,\n",
       " 'use_bfloat16': False,\n",
       " 'tf_legacy_loss': False,\n",
       " 'pruned_heads': {},\n",
       " 'tie_word_embeddings': True,\n",
       " 'is_encoder_decoder': False,\n",
       " 'is_decoder': False,\n",
       " 'cross_attention_hidden_size': None,\n",
       " 'add_cross_attention': False,\n",
       " 'tie_encoder_decoder': False,\n",
       " 'max_length': 20,\n",
       " 'min_length': 0,\n",
       " 'do_sample': False,\n",
       " 'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'num_beam_groups': 1,\n",
       " 'diversity_penalty': 0.0,\n",
       " 'temperature': 1.0,\n",
       " 'top_k': 50,\n",
       " 'top_p': 1.0,\n",
       " 'typical_p': 1.0,\n",
       " 'repetition_penalty': 1.0,\n",
       " 'length_penalty': 1.0,\n",
       " 'no_repeat_ngram_size': 0,\n",
       " 'encoder_no_repeat_ngram_size': 0,\n",
       " 'bad_words_ids': None,\n",
       " 'num_return_sequences': 1,\n",
       " 'chunk_size_feed_forward': 0,\n",
       " 'output_scores': False,\n",
       " 'return_dict_in_generate': False,\n",
       " 'forced_bos_token_id': None,\n",
       " 'forced_eos_token_id': None,\n",
       " 'remove_invalid_values': False,\n",
       " 'exponential_decay_length_penalty': None,\n",
       " 'suppress_tokens': None,\n",
       " 'begin_suppress_tokens': None,\n",
       " 'architectures': None,\n",
       " 'finetuning_task': None,\n",
       " 'id2label': {0: 'LABEL_0',\n",
       "  1: 'LABEL_1',\n",
       "  2: 'LABEL_2',\n",
       "  3: 'LABEL_3',\n",
       "  4: 'LABEL_4',\n",
       "  5: 'LABEL_5',\n",
       "  6: 'LABEL_6',\n",
       "  7: 'LABEL_7',\n",
       "  8: 'LABEL_8',\n",
       "  9: 'LABEL_9',\n",
       "  10: 'LABEL_10',\n",
       "  11: 'LABEL_11',\n",
       "  12: 'LABEL_12',\n",
       "  13: 'LABEL_13',\n",
       "  14: 'LABEL_14',\n",
       "  15: 'LABEL_15',\n",
       "  16: 'LABEL_16',\n",
       "  17: 'LABEL_17',\n",
       "  18: 'LABEL_18',\n",
       "  19: 'LABEL_19',\n",
       "  20: 'LABEL_20',\n",
       "  21: 'LABEL_21',\n",
       "  22: 'LABEL_22',\n",
       "  23: 'LABEL_23',\n",
       "  24: 'LABEL_24',\n",
       "  25: 'LABEL_25',\n",
       "  26: 'LABEL_26',\n",
       "  27: 'LABEL_27',\n",
       "  28: 'LABEL_28',\n",
       "  29: 'LABEL_29',\n",
       "  30: 'LABEL_30',\n",
       "  31: 'LABEL_31',\n",
       "  32: 'LABEL_32',\n",
       "  33: 'LABEL_33',\n",
       "  34: 'LABEL_34',\n",
       "  35: 'LABEL_35',\n",
       "  36: 'LABEL_36',\n",
       "  37: 'LABEL_37',\n",
       "  38: 'LABEL_38',\n",
       "  39: 'LABEL_39',\n",
       "  40: 'LABEL_40',\n",
       "  41: 'LABEL_41',\n",
       "  42: 'LABEL_42',\n",
       "  43: 'LABEL_43',\n",
       "  44: 'LABEL_44',\n",
       "  45: 'LABEL_45',\n",
       "  46: 'LABEL_46',\n",
       "  47: 'LABEL_47',\n",
       "  48: 'LABEL_48',\n",
       "  49: 'LABEL_49',\n",
       "  50: 'LABEL_50',\n",
       "  51: 'LABEL_51',\n",
       "  52: 'LABEL_52',\n",
       "  53: 'LABEL_53',\n",
       "  54: 'LABEL_54',\n",
       "  55: 'LABEL_55',\n",
       "  56: 'LABEL_56',\n",
       "  57: 'LABEL_57',\n",
       "  58: 'LABEL_58',\n",
       "  59: 'LABEL_59',\n",
       "  60: 'LABEL_60',\n",
       "  61: 'LABEL_61',\n",
       "  62: 'LABEL_62',\n",
       "  63: 'LABEL_63',\n",
       "  64: 'LABEL_64',\n",
       "  65: 'LABEL_65',\n",
       "  66: 'LABEL_66',\n",
       "  67: 'LABEL_67',\n",
       "  68: 'LABEL_68',\n",
       "  69: 'LABEL_69',\n",
       "  70: 'LABEL_70',\n",
       "  71: 'LABEL_71',\n",
       "  72: 'LABEL_72',\n",
       "  73: 'LABEL_73',\n",
       "  74: 'LABEL_74',\n",
       "  75: 'LABEL_75',\n",
       "  76: 'LABEL_76',\n",
       "  77: 'LABEL_77',\n",
       "  78: 'LABEL_78',\n",
       "  79: 'LABEL_79',\n",
       "  80: 'LABEL_80',\n",
       "  81: 'LABEL_81',\n",
       "  82: 'LABEL_82',\n",
       "  83: 'LABEL_83',\n",
       "  84: 'LABEL_84',\n",
       "  85: 'LABEL_85',\n",
       "  86: 'LABEL_86',\n",
       "  87: 'LABEL_87',\n",
       "  88: 'LABEL_88',\n",
       "  89: 'LABEL_89',\n",
       "  90: 'LABEL_90',\n",
       "  91: 'LABEL_91',\n",
       "  92: 'LABEL_92',\n",
       "  93: 'LABEL_93',\n",
       "  94: 'LABEL_94',\n",
       "  95: 'LABEL_95',\n",
       "  96: 'LABEL_96',\n",
       "  97: 'LABEL_97',\n",
       "  98: 'LABEL_98',\n",
       "  99: 'LABEL_99'},\n",
       " 'label2id': {'LABEL_0': 0,\n",
       "  'LABEL_1': 1,\n",
       "  'LABEL_2': 2,\n",
       "  'LABEL_3': 3,\n",
       "  'LABEL_4': 4,\n",
       "  'LABEL_5': 5,\n",
       "  'LABEL_6': 6,\n",
       "  'LABEL_7': 7,\n",
       "  'LABEL_8': 8,\n",
       "  'LABEL_9': 9,\n",
       "  'LABEL_10': 10,\n",
       "  'LABEL_11': 11,\n",
       "  'LABEL_12': 12,\n",
       "  'LABEL_13': 13,\n",
       "  'LABEL_14': 14,\n",
       "  'LABEL_15': 15,\n",
       "  'LABEL_16': 16,\n",
       "  'LABEL_17': 17,\n",
       "  'LABEL_18': 18,\n",
       "  'LABEL_19': 19,\n",
       "  'LABEL_20': 20,\n",
       "  'LABEL_21': 21,\n",
       "  'LABEL_22': 22,\n",
       "  'LABEL_23': 23,\n",
       "  'LABEL_24': 24,\n",
       "  'LABEL_25': 25,\n",
       "  'LABEL_26': 26,\n",
       "  'LABEL_27': 27,\n",
       "  'LABEL_28': 28,\n",
       "  'LABEL_29': 29,\n",
       "  'LABEL_30': 30,\n",
       "  'LABEL_31': 31,\n",
       "  'LABEL_32': 32,\n",
       "  'LABEL_33': 33,\n",
       "  'LABEL_34': 34,\n",
       "  'LABEL_35': 35,\n",
       "  'LABEL_36': 36,\n",
       "  'LABEL_37': 37,\n",
       "  'LABEL_38': 38,\n",
       "  'LABEL_39': 39,\n",
       "  'LABEL_40': 40,\n",
       "  'LABEL_41': 41,\n",
       "  'LABEL_42': 42,\n",
       "  'LABEL_43': 43,\n",
       "  'LABEL_44': 44,\n",
       "  'LABEL_45': 45,\n",
       "  'LABEL_46': 46,\n",
       "  'LABEL_47': 47,\n",
       "  'LABEL_48': 48,\n",
       "  'LABEL_49': 49,\n",
       "  'LABEL_50': 50,\n",
       "  'LABEL_51': 51,\n",
       "  'LABEL_52': 52,\n",
       "  'LABEL_53': 53,\n",
       "  'LABEL_54': 54,\n",
       "  'LABEL_55': 55,\n",
       "  'LABEL_56': 56,\n",
       "  'LABEL_57': 57,\n",
       "  'LABEL_58': 58,\n",
       "  'LABEL_59': 59,\n",
       "  'LABEL_60': 60,\n",
       "  'LABEL_61': 61,\n",
       "  'LABEL_62': 62,\n",
       "  'LABEL_63': 63,\n",
       "  'LABEL_64': 64,\n",
       "  'LABEL_65': 65,\n",
       "  'LABEL_66': 66,\n",
       "  'LABEL_67': 67,\n",
       "  'LABEL_68': 68,\n",
       "  'LABEL_69': 69,\n",
       "  'LABEL_70': 70,\n",
       "  'LABEL_71': 71,\n",
       "  'LABEL_72': 72,\n",
       "  'LABEL_73': 73,\n",
       "  'LABEL_74': 74,\n",
       "  'LABEL_75': 75,\n",
       "  'LABEL_76': 76,\n",
       "  'LABEL_77': 77,\n",
       "  'LABEL_78': 78,\n",
       "  'LABEL_79': 79,\n",
       "  'LABEL_80': 80,\n",
       "  'LABEL_81': 81,\n",
       "  'LABEL_82': 82,\n",
       "  'LABEL_83': 83,\n",
       "  'LABEL_84': 84,\n",
       "  'LABEL_85': 85,\n",
       "  'LABEL_86': 86,\n",
       "  'LABEL_87': 87,\n",
       "  'LABEL_88': 88,\n",
       "  'LABEL_89': 89,\n",
       "  'LABEL_90': 90,\n",
       "  'LABEL_91': 91,\n",
       "  'LABEL_92': 92,\n",
       "  'LABEL_93': 93,\n",
       "  'LABEL_94': 94,\n",
       "  'LABEL_95': 95,\n",
       "  'LABEL_96': 96,\n",
       "  'LABEL_97': 97,\n",
       "  'LABEL_98': 98,\n",
       "  'LABEL_99': 99},\n",
       " 'tokenizer_class': None,\n",
       " 'prefix': None,\n",
       " 'bos_token_id': None,\n",
       " 'pad_token_id': None,\n",
       " 'eos_token_id': None,\n",
       " 'sep_token_id': None,\n",
       " 'decoder_start_token_id': None,\n",
       " 'task_specific_params': None,\n",
       " 'problem_type': None,\n",
       " '_name_or_path': '',\n",
       " '_commit_hash': None,\n",
       " 'transformers_version': None,\n",
       " 'hidden_size': 768,\n",
       " 'num_hidden_layers': 12,\n",
       " 'num_attention_heads': 12,\n",
       " 'intermediate_size': 3072,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.0,\n",
       " 'attention_probs_dropout_prob': 0.0,\n",
       " 'initializer_range': 0.02,\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'image_size': 128,\n",
       " 'patch_size': 8,\n",
       " 'num_channels': 3,\n",
       " 'qkv_bias': True,\n",
       " 'encoder_stride': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config128_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
